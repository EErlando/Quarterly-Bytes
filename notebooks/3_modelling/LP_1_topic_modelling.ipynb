{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3390045b",
      "metadata": {
        "id": "3390045b"
      },
      "source": [
        "# Setup, Constants, and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "70ea4469",
      "metadata": {
        "id": "70ea4469"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import logging"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd643fb0",
      "metadata": {
        "id": "fd643fb0"
      },
      "source": [
        "## Notebook Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "3c08565b",
      "metadata": {
        "id": "3c08565b"
      },
      "outputs": [],
      "source": [
        "IS_COLAB = 'google.colab' in sys.modules\n",
        "OUTPUT_PROCESSED_FILES = False # TODO: Use this if you want to output save files (optional - see below)\n",
        "\n",
        "if IS_COLAB:\n",
        "    from google.colab import userdata\n",
        "    GITHUB_USERNAME = userdata.get('github_user')\n",
        "    GITHUB_TOKEN = userdata.get('github_token')\n",
        "    GITHUB_EMAIL = userdata.get('github_email')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd9d4e41",
      "metadata": {
        "id": "cd9d4e41"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "5129180d",
      "metadata": {
        "id": "5129180d"
      },
      "outputs": [],
      "source": [
        "REPO_URL = \"https://github.com/EErlando/Quarterly-Bytes.git\"\n",
        "REPO_NAME = \"src\"\n",
        "REPO_BRANCH = \"LP_topic_modelling_extended\" # TODO: UPDATE THIS TO YOU BRANCH - DEFAULT TO MAIN\n",
        "NOTEBOOK_DIR = \"3_modelling\" # TODO: UPDATE THIS TO YOUR NOTEBOOK DIRECTORY (e.g. 1_data_extraction_and_processing)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0864529e",
      "metadata": {
        "id": "0864529e"
      },
      "source": [
        "## Clone and Pull Latest from Repository - Colab Specific"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "91c87440",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91c87440",
        "outputId": "b4579e3e-4abc-4e20-c1a5-592b174465ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'src' already exists. Pulling latest changes...\n",
            "/content/src/src\n",
            "/content/src\n",
            "/content/src\n",
            "Requirement already satisfied: PyPDF2==3.0.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (3.0.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.6.1)\n",
            "Requirement already satisfied: nltk>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (3.9.1)\n",
            "Requirement already satisfied: spacy>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.8.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.13.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (4.52.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (2.0.2)\n",
            "Requirement already satisfied: bertopic in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (0.17.0)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.5.7)\n",
            "Requirement already satisfied: python-dev-tools in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (2023.3.24)\n",
            "Requirement already satisfied: hdbscan==0.8.40 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (0.8.40)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (4.1.0)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan==0.8.40->-r requirements.txt (line 15)) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan==0.8.40->-r requirements.txt (line 15)) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.0->-r requirements.txt (line 4)) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.0->-r requirements.txt (line 4)) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.0->-r requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (0.16.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (3.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 9)) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 10)) (0.33.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 10)) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 10)) (0.5.3)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from bertopic->-r requirements.txt (line 12)) (5.24.1)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn->-r requirements.txt (line 13)) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn->-r requirements.txt (line 13)) (0.5.13)\n",
            "Requirement already satisfied: Sphinx<7,>=6 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (6.2.1)\n",
            "Requirement already satisfied: autoflake<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.7.8)\n",
            "Requirement already satisfied: black<24,>=23 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (23.12.1)\n",
            "Requirement already satisfied: coverage[toml]<8,>=7 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (7.9.1)\n",
            "Requirement already satisfied: darglint<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.8.1)\n",
            "Requirement already satisfied: dlint<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.16.0)\n",
            "Requirement already satisfied: doc8<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.1.2)\n",
            "Requirement already satisfied: docformatter<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.7.7)\n",
            "Requirement already satisfied: flake8<6,>=5 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (5.0.4)\n",
            "Requirement already satisfied: flake8-2020<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.8.1)\n",
            "Requirement already satisfied: flake8-aaa<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.17.0)\n",
            "Requirement already satisfied: flake8-annotations<4,>=3 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (3.1.1)\n",
            "Requirement already satisfied: flake8-annotations-complexity<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.1.0)\n",
            "Requirement already satisfied: flake8-annotations-coverage<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.0.6)\n",
            "Requirement already satisfied: flake8-bandit<5,>=4 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (4.1.1)\n",
            "Requirement already satisfied: flake8-black<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.3.6)\n",
            "Requirement already satisfied: flake8-blind-except<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.2.1)\n",
            "Requirement already satisfied: flake8-breakpoint<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.1.0)\n",
            "Requirement already satisfied: flake8-broken-line<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.6.0)\n",
            "Requirement already satisfied: flake8-bugbear<24,>=23 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (23.3.12)\n",
            "Requirement already satisfied: flake8-builtins<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.5.3)\n",
            "Requirement already satisfied: flake8-class-attributes-order<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.3.0)\n",
            "Requirement already satisfied: flake8-coding<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.3.2)\n",
            "Requirement already satisfied: flake8-cognitive-complexity<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.1.0)\n",
            "Requirement already satisfied: flake8-comments<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.1.2)\n",
            "Requirement already satisfied: flake8-comprehensions<4,>=3 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (3.16.0)\n",
            "Requirement already satisfied: flake8-debugger<5,>=4 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (4.1.2)\n",
            "Requirement already satisfied: flake8-django<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.4)\n",
            "Requirement already satisfied: flake8-docstrings<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.7.0)\n",
            "Requirement already satisfied: flake8-encodings<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.5.1)\n",
            "Requirement already satisfied: flake8-eradicate<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.5.0)\n",
            "Requirement already satisfied: flake8-executable<3,>=2 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (2.1.3)\n",
            "Requirement already satisfied: flake8-expression-complexity<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.0.11)\n",
            "Requirement already satisfied: flake8-fastapi<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.7.0)\n",
            "Requirement already satisfied: flake8-fixme<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.1.1)\n",
            "Requirement already satisfied: flake8-functions<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.0.8)\n",
            "Requirement already satisfied: flake8-functions-names<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.4.0)\n",
            "Requirement already satisfied: flake8-future-annotations<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.0.5)\n",
            "Requirement already satisfied: flake8-isort<7,>=6 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (6.1.2)\n",
            "Requirement already satisfied: flake8-literal<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.4.0)\n",
            "Requirement already satisfied: flake8-logging-format<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.9.0)\n",
            "Requirement already satisfied: flake8-markdown<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.6.0)\n",
            "Requirement already satisfied: flake8-mutable<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.2.0)\n",
            "Requirement already satisfied: flake8-no-pep420<3,>=2 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (2.8.0)\n",
            "Requirement already satisfied: flake8-noqa<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.4.0)\n",
            "Requirement already satisfied: flake8-pie<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.16.0)\n",
            "Requirement already satisfied: flake8-pyi<23,>=22 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (22.11.0)\n",
            "Requirement already satisfied: flake8-pylint<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.2.1)\n",
            "Requirement already satisfied: flake8-pytest-style<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.7.2)\n",
            "Requirement already satisfied: flake8-quotes<4,>=3 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (3.4.0)\n",
            "Requirement already satisfied: flake8-rst-docstrings<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.3.1)\n",
            "Requirement already satisfied: flake8-secure-coding-standard<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.4.1)\n",
            "Requirement already satisfied: flake8-simplify<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.22.0)\n",
            "Requirement already satisfied: flake8-string-format<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.3.0)\n",
            "Requirement already satisfied: flake8-tidy-imports<5,>=4 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (4.11.0)\n",
            "Requirement already satisfied: flake8-typing-imports<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.16.0)\n",
            "Requirement already satisfied: flake8-use-fstring<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.4)\n",
            "Requirement already satisfied: flake8-use-pathlib<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.3.0)\n",
            "Requirement already satisfied: flake8-useless-assert<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.4.4)\n",
            "Requirement already satisfied: flake8-variables-names<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.0.6)\n",
            "Requirement already satisfied: flake8-warnings<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.4.0)\n",
            "Requirement already satisfied: jupyterlab-flake8<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.7.1)\n",
            "Requirement already satisfied: pandas-vet<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.2.3)\n",
            "Requirement already satisfied: pep8-naming<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.15.1)\n",
            "Requirement already satisfied: pip<23,>=22 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (22.3.1)\n",
            "Requirement already satisfied: pybetter<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.4.1)\n",
            "Requirement already satisfied: pycln<3,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (2.5.0)\n",
            "Requirement already satisfied: pycodestyle<3,>=2 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (2.9.1)\n",
            "Requirement already satisfied: pydocstyle<7,>=6 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (6.3.0)\n",
            "Requirement already satisfied: pytest<8,>=7 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (7.4.4)\n",
            "Requirement already satisfied: pytest-cov<5,>=4 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (4.1.0)\n",
            "Requirement already satisfied: pytest-sugar<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.9.7)\n",
            "Requirement already satisfied: pyupgrade<4,>=3 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (3.20.0)\n",
            "Requirement already satisfied: removestar<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.5.2)\n",
            "Requirement already satisfied: ssort<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.14.0)\n",
            "Requirement already satisfied: tox<5,>=4 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (4.27.0)\n",
            "Requirement already satisfied: tox-travis<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.12)\n",
            "Requirement already satisfied: pyflakes<3,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from autoflake<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (2.5.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from black<24,>=23->python-dev-tools->-r requirements.txt (line 14)) (1.1.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from black<24,>=23->python-dev-tools->-r requirements.txt (line 14)) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black<24,>=23->python-dev-tools->-r requirements.txt (line 14)) (4.3.8)\n",
            "Requirement already satisfied: docutils<=0.21.2,>=0.19 in /usr/local/lib/python3.11/dist-packages (from doc8<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (0.19)\n",
            "Requirement already satisfied: restructuredtext-lint>=0.7 in /usr/local/lib/python3.11/dist-packages (from doc8<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (1.4.0)\n",
            "Requirement already satisfied: stevedore in /usr/local/lib/python3.11/dist-packages (from doc8<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (5.4.1)\n",
            "Requirement already satisfied: Pygments in /usr/local/lib/python3.11/dist-packages (from doc8<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (2.19.1)\n",
            "Requirement already satisfied: charset_normalizer<4.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from docformatter<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (3.4.2)\n",
            "Requirement already satisfied: untokenize<0.2.0,>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from docformatter<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (0.1.1)\n",
            "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from flake8<6,>=5->python-dev-tools->-r requirements.txt (line 14)) (0.7.0)\n",
            "Requirement already satisfied: asttokens>=2 in /usr/local/lib/python3.11/dist-packages (from flake8-aaa<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (3.0.0)\n",
            "Requirement already satisfied: attrs>=21.4 in /usr/local/lib/python3.11/dist-packages (from flake8-annotations<4,>=3->python-dev-tools->-r requirements.txt (line 14)) (25.3.0)\n",
            "Requirement already satisfied: bandit>=1.7.3 in /usr/local/lib/python3.11/dist-packages (from flake8-bandit<5,>=4->python-dev-tools->-r requirements.txt (line 14)) (1.8.5)\n",
            "Requirement already satisfied: flake8-plugin-utils<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from flake8-breakpoint<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (1.3.3)\n",
            "Requirement already satisfied: cognitive-complexity in /usr/local/lib/python3.11/dist-packages (from flake8-cognitive-complexity<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (1.3.0)\n",
            "Requirement already satisfied: astroid<3.0.0,>=2.15.2 in /usr/local/lib/python3.11/dist-packages (from flake8-django<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (2.15.8)\n",
            "Requirement already satisfied: astatine>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from flake8-encodings<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.3.3)\n",
            "Requirement already satisfied: domdf-python-tools>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from flake8-encodings<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (3.10.0)\n",
            "Requirement already satisfied: flake8-helper>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from flake8-encodings<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.2.2)\n",
            "Requirement already satisfied: eradicate<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from flake8-eradicate<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (2.3.0)\n",
            "Requirement already satisfied: astpretty in /usr/local/lib/python3.11/dist-packages (from flake8-expression-complexity<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (3.0.0)\n",
            "Requirement already satisfied: fastapi>=0.65.1 in /usr/local/lib/python3.11/dist-packages (from flake8-fastapi<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.115.12)\n",
            "Requirement already satisfied: mr-proper in /usr/local/lib/python3.11/dist-packages (from flake8-functions<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.0.7)\n",
            "Requirement already satisfied: isort<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from flake8-isort<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (5.13.2)\n",
            "Requirement already satisfied: pylint in /usr/local/lib/python3.11/dist-packages (from flake8-pylint<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (2.17.7)\n",
            "Requirement already satisfied: astor>=0.1 in /usr/local/lib/python3.11/dist-packages (from flake8-simplify<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.8.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->-r requirements.txt (line 10)) (1.1.3)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.0.0->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn->-r requirements.txt (line 13)) (0.43.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic->-r requirements.txt (line 12)) (9.1.2)\n",
            "Requirement already satisfied: hypothesmith<0.2.0,>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from pybetter<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.1.9)\n",
            "Requirement already satisfied: libcst<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from pybetter<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.4.10)\n",
            "Requirement already satisfied: pyemojify<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from pybetter<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.2.0)\n",
            "Requirement already satisfied: tomlkit>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from pycln<3,>=1->python-dev-tools->-r requirements.txt (line 14)) (0.13.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.0->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.0->-r requirements.txt (line 5)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.0->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: snowballstemmer>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pydocstyle<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (3.0.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest<8,>=7->python-dev-tools->-r requirements.txt (line 14)) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from pytest<8,>=7->python-dev-tools->-r requirements.txt (line 14)) (1.6.0)\n",
            "Requirement already satisfied: termcolor>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytest-sugar<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 2)) (1.17.0)\n",
            "Requirement already satisfied: tokenize-rt>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from pyupgrade<4,>=3->python-dev-tools->-r requirements.txt (line 14)) (6.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->-r requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->-r requirements.txt (line 5)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->-r requirements.txt (line 5)) (2025.6.15)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.11/dist-packages (from Sphinx<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.11/dist-packages (from Sphinx<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.11/dist-packages (from Sphinx<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from Sphinx<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from Sphinx<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.11/dist-packages (from Sphinx<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (2.0.0)\n",
            "Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.11/dist-packages (from Sphinx<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (2.17.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.11/dist-packages (from Sphinx<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (0.7.16)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from Sphinx<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (1.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy>=3.0.0->-r requirements.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.0.0->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.0.0->-r requirements.txt (line 5)) (0.1.5)\n",
            "Requirement already satisfied: cachetools>=5.5.1 in /usr/local/lib/python3.11/dist-packages (from tox<5,>=4->python-dev-tools->-r requirements.txt (line 14)) (5.5.2)\n",
            "Requirement already satisfied: chardet>=5.2 in /usr/local/lib/python3.11/dist-packages (from tox<5,>=4->python-dev-tools->-r requirements.txt (line 14)) (5.2.0)\n",
            "Requirement already satisfied: colorama>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from tox<5,>=4->python-dev-tools->-r requirements.txt (line 14)) (0.4.6)\n",
            "Requirement already satisfied: pyproject-api>=1.8 in /usr/local/lib/python3.11/dist-packages (from tox<5,>=4->python-dev-tools->-r requirements.txt (line 14)) (1.9.1)\n",
            "Requirement already satisfied: virtualenv>=20.31 in /usr/local/lib/python3.11/dist-packages (from tox<5,>=4->python-dev-tools->-r requirements.txt (line 14)) (20.31.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.0.0->-r requirements.txt (line 5)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.0.0->-r requirements.txt (line 5)) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.0.0->-r requirements.txt (line 5)) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.0.0->-r requirements.txt (line 5)) (7.1.0)\n",
            "Requirement already satisfied: lazy-object-proxy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from astroid<3.0.0,>=2.15.2->flake8-django<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (1.11.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.14 in /usr/local/lib/python3.11/dist-packages (from astroid<3.0.0,>=2.15.2->flake8-django<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (1.17.2)\n",
            "Requirement already satisfied: natsort>=7.0.1 in /usr/local/lib/python3.11/dist-packages (from domdf-python-tools>=2.8.1->flake8-encodings<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (8.4.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.65.1->flake8-fastapi<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.46.2)\n",
            "Requirement already satisfied: hypothesis>=5.41.0 in /usr/local/lib/python3.11/dist-packages (from hypothesmith<0.2.0,>=0.1.8->pybetter<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (6.135.11)\n",
            "Requirement already satisfied: lark-parser>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from hypothesmith<0.2.0,>=0.1.8->pybetter<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.12.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.0.0->-r requirements.txt (line 5)) (1.2.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from libcst<0.5.0,>=0.4.1->pybetter<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.9.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.0.0->-r requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore->doc8<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (6.1.1)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.31->tox<5,>=4->python-dev-tools->-r requirements.txt (line 14)) (0.3.9)\n",
            "Requirement already satisfied: stdlib-list>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from mr-proper->flake8-functions<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.11.1)\n",
            "Requirement already satisfied: dill>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from pylint->flake8-pylint<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.3.7)\n",
            "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from hypothesis>=5.41.0->hypothesmith<0.2.0,>=0.1.8->pybetter<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.0.0->-r requirements.txt (line 5)) (0.1.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi>=0.65.1->flake8-fastapi<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi>=0.65.1->flake8-fastapi<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "if IS_COLAB:\n",
        "    !git config pull.rebase false\n",
        "    if os.path.exists(REPO_NAME):\n",
        "        print(f\"Directory '{REPO_NAME}' already exists. Pulling latest changes...\")\n",
        "        %cd {REPO_NAME}\n",
        "        !git pull origin {REPO_BRANCH} --quiet\n",
        "        %cd ..\n",
        "    else:\n",
        "        print(f\"Cloning repository into '{REPO_NAME}'...\")\n",
        "        !git clone --quiet --branch {REPO_BRANCH} {REPO_URL} {REPO_NAME}\n",
        "        print(\"Clone complete.\")\n",
        "\n",
        "    sys.path.append('/content/src/')\n",
        "    %cd /content/src/\n",
        "    !pip install -r requirements.txt\n",
        "else:\n",
        "    if os.path.basename(os.getcwd()) == NOTEBOOK_DIR:\n",
        "        os.chdir('../../') # TODO: UPDATE THIS TO ROOT OF REPO\n",
        "\n",
        "    !pip install -r requirements.txt\n",
        "\n",
        "logging.basicConfig(level=logging.ERROR, format='%(levelname)s: %(message)s')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post Install Imports"
      ],
      "metadata": {
        "id": "ryvB1Hpx1C3V"
      },
      "id": "ryvB1Hpx1C3V"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "import os\n",
        "!pip install bertopic\n",
        "\n",
        "from bertopic import BERTopic\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4EyBg8j1FgP",
        "outputId": "bee89612-65ac-440a-b658-6fb8636fc66b"
      },
      "id": "x4EyBg8j1FgP",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bertopic in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
            "Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.8.40)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from bertopic) (2.2.2)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (5.24.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from bertopic) (4.1.0)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.11/dist-packages (from bertopic) (4.67.1)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.5.7)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (25.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->bertopic) (3.6.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.52.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.33.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.14.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (1.1.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "02d72bb0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02d72bb0",
        "outputId": "8f9603e9-047e-48ea-a8c7-db59c43b6cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6147c7a",
      "metadata": {
        "id": "c6147c7a"
      },
      "source": [
        "## Local Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "f2963e1f",
      "metadata": {
        "id": "f2963e1f"
      },
      "outputs": [],
      "source": [
        "from src.utils.common_helpers import read_yaml_file, read_list_from_text_file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2569d135",
      "metadata": {
        "id": "2569d135"
      },
      "source": [
        "## Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "a60bdaad",
      "metadata": {
        "id": "a60bdaad"
      },
      "outputs": [],
      "source": [
        "def group_df(df, group_by_columns, agg_column='content'):\n",
        "    \"\"\"\n",
        "    Groups the DataFrame by specified columns and aggregates the content column.\n",
        "\n",
        "    Parameters:\n",
        "    - df: DataFrame to group\n",
        "    - group_by_columns: List of columns to group by\n",
        "    - agg_column: Column to aggregate (default is 'content')\n",
        "\n",
        "    Returns:\n",
        "    - Grouped DataFrame with aggregated content\n",
        "    \"\"\"\n",
        "    return df.groupby(group_by_columns, as_index=False).agg({agg_column: ' '.join})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62b50738",
      "metadata": {
        "id": "62b50738"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "4f87c1ff",
      "metadata": {
        "id": "4f87c1ff"
      },
      "outputs": [],
      "source": [
        "gs_discussion_df = pd.read_csv('data/processed/Goldman Sachs/discussion_df.csv')\n",
        "gs_qna_df = pd.read_csv('data/processed/Goldman Sachs/qna_df.csv')\n",
        "jp_discussion_df = pd.read_csv('data/processed/JP Morgan/discussion_df.csv')\n",
        "jp_qna_df = pd.read_csv('data/processed/JP Morgan/qna_df.csv')\n",
        "\n",
        "\n",
        "# Goldman Sachs\n",
        "grouped_gs_discussion_df = group_df(gs_discussion_df, ['quarter', 'year'])\n",
        "grouped_gs_qna_df = group_df(gs_qna_df, ['question_answer_group_id', 'quarter', 'year'])\n",
        "\n",
        "# JP Morgan\n",
        "grouped_jp_discussion_df = group_df(jp_discussion_df, ['quarter', 'year'])\n",
        "grouped_jp_qna_df = group_df(jp_qna_df, ['question_answer_group_id', 'quarter', 'year'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73420e11",
      "metadata": {
        "id": "73420e11"
      },
      "source": [
        "# Topic Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "23cf4579",
      "metadata": {
        "id": "23cf4579"
      },
      "outputs": [],
      "source": [
        "gs_stopwords = set(read_list_from_text_file('src/data_processing/goldman_sachs_topic_modelling_stopwords.txt'))\n",
        "abbreviations = read_yaml_file('src/abbreviations.yaml')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/pdf/2504.15683\n",
        "Use FinTextSim"
      ],
      "metadata": {
        "id": "Ctb_E-tzCBU_"
      },
      "id": "Ctb_E-tzCBU_"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "b95b9b4e",
      "metadata": {
        "id": "b95b9b4e"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
        "except OSError:\n",
        "    print(\"SpaCy 'en_core_web_sm' model not found. Please run: python -m spacy download en_core_web_sm\")\n",
        "    exit()\n",
        "\n",
        "gs_stopwords = nlp.Defaults.stop_words.union(gs_stopwords)\n",
        "\n",
        "def preprocess_text(text: str, stop_words: set, abbreviations: dict) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    processed_text = text.lower()\n",
        "    processed_text = re.sub(r'[-_]+', ' ', processed_text).strip()\n",
        "\n",
        "    sorted_phrases = sorted(abbreviations.items(), key=lambda item: len(item[1]), reverse=True)\n",
        "\n",
        "    for abbrev, phrase in sorted_phrases:\n",
        "        processed_text = re.sub(r'\\b' + re.escape(phrase.lower()) + r'\\b', abbrev.lower(), processed_text)\n",
        "\n",
        "    processed_text = re.sub(r'\\b\\d+\\b', '', processed_text).strip()\n",
        "\n",
        "    doc = nlp(processed_text)\n",
        "\n",
        "    tokens = []\n",
        "    for token in doc:\n",
        "        if token.text not in stop_words or token.text in abbreviations.keys():\n",
        "            tokens.append(token.lemma_) # Lemmatize the token (abbreviations won't change)\n",
        "\n",
        "    return \" \".join(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "fb801083",
      "metadata": {
        "id": "fb801083"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.pipeline import Pipeline\n",
        "import os\n",
        "from bertopic import BERTopic\n",
        "from umap import UMAP\n",
        "import hdbscan\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "\n",
        "# --- Mock Preprocessing Function (replace with your actual preprocess_text) ---\n",
        "# def preprocess_text(text, stop_words=None, abbreviations=None):\n",
        "#     \"\"\"\n",
        "#     A mock preprocessing function to clean and prepare text.\n",
        "#     In a real application, this would include tokenization, stemming/lemmatization,\n",
        "#     punctuation removal, number handling, etc.\n",
        "#     \"\"\"\n",
        "#     text = str(text).lower()\n",
        "#     # Simple tokenization and stop word removal for demonstration\n",
        "#     words = text.split()\n",
        "#     if stop_words:\n",
        "#         words = [word for word in words if word not in stop_words]\n",
        "#     # Simple abbreviation handling (example: 'ai' -> 'artificial intelligence')\n",
        "#     if abbreviations:\n",
        "#         for abbr, full in abbreviations.items():\n",
        "#             words = [full if word == abbr else word for word in words]\n",
        "#     return \" \".join(words)\n",
        "\n",
        "\n",
        "def preprocess_text(text: str, stop_words: set, abbreviations: dict) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    processed_text = text.lower()\n",
        "    processed_text = re.sub(r'[-_]+', ' ', processed_text).strip()\n",
        "\n",
        "    sorted_phrases = sorted(abbreviations.items(), key=lambda item: len(item[1]), reverse=True)\n",
        "\n",
        "    for abbrev, phrase in sorted_phrases:\n",
        "        processed_text = re.sub(r'\\b' + re.escape(phrase.lower()) + r'\\b', abbrev.lower(), processed_text)\n",
        "\n",
        "    processed_text = re.sub(r'\\b\\d+\\b', '', processed_text).strip()\n",
        "\n",
        "    doc = nlp(processed_text)\n",
        "\n",
        "    tokens = []\n",
        "    for token in doc:\n",
        "        if token.text not in stop_words or token.text in abbreviations.keys():\n",
        "            tokens.append(token.lemma_) # Lemmatize the token (abbreviations won't change)\n",
        "\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# --- Custom Transformer for Text Preprocessing ---\n",
        "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    A custom scikit-learn transformer to apply text preprocessing.\n",
        "    It wraps the 'preprocess_text' function.\n",
        "    \"\"\"\n",
        "    def __init__(self, stop_words=None, abbreviations=None):\n",
        "        self.stop_words = stop_words\n",
        "        self.abbreviations = abbreviations\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        print(\"Starting Phase 1: Preprocessing...\")\n",
        "        preprocessed_X = [preprocess_text(text, self.stop_words, self.abbreviations) for text in X]\n",
        "        print(\"Preprocessing complete.\")\n",
        "        return pd.Series(preprocessed_X)\n",
        "\n",
        "\n",
        "# --- Custom Estimator for BERTopic Modeling ---\n",
        "class BERTopicWrapper(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    A custom scikit-learn estimator that wraps BERTopic.\n",
        "    \"\"\"\n",
        "    def __init__(self, embedding_model='all-MiniLM-L6-v2', umap_args=None, hdbscan_args=None,\n",
        "                 vectorizer_args=None, nr_topics=\"auto\", calculate_probabilities=True, **bertopic_kwargs):\n",
        "\n",
        "        self.embedding_model_name = embedding_model\n",
        "        self.umap_args = umap_args if umap_args is not None else {}\n",
        "        self.hdbscan_args = hdbscan_args if hdbscan_args is not None else {}\n",
        "        self.vectorizer_args = vectorizer_args if vectorizer_args is not None else {}\n",
        "        self.nr_topics = nr_topics\n",
        "        self.calculate_probabilities = calculate_probabilities\n",
        "        self.bertopic_kwargs = bertopic_kwargs\n",
        "        self.bertopic_model = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        print(\"\\nStarting Phase 3: Topic Modeling (BERTopic)...\")\n",
        "\n",
        "        # Initialize UMAP and HDBSCAN models\n",
        "        umap_model = UMAP(**self.umap_args)\n",
        "        hdbscan_model = hdbscan.HDBSCAN(\n",
        "            min_cluster_size=10,  # Default, can be overridden by hdbscan_args\n",
        "            metric='euclidean',\n",
        "            cluster_selection_method='eom',\n",
        "            prediction_data=True, # Required for transform to assign topics to new data\n",
        "            **self.hdbscan_args\n",
        "        )\n",
        "\n",
        "        # Initialize SentenceTransformer\n",
        "        embedding_model = SentenceTransformer(self.embedding_model_name)\n",
        "\n",
        "        default_min_df_for_bertopic_vectorizer = 1 # Changed from 10 to 1 for higher permissiveness\n",
        "\n",
        "        # Combine default vectorizer args with user-provided args\n",
        "        combined_vectorizer_args = {\n",
        "            'min_df': default_min_df_for_bertopic_vectorizer,\n",
        "            'ngram_range': (1, 3), # Common default for BERTopic's internal vectorizer\n",
        "            **self.vectorizer_args # User-provided vectorizer_args will override these defaults\n",
        "        }\n",
        "\n",
        "        vectorizer_model = TfidfVectorizer(**combined_vectorizer_args)\n",
        "\n",
        "\n",
        "        self.bertopic_model = BERTopic(\n",
        "            embedding_model=embedding_model,\n",
        "            umap_model=umap_model,\n",
        "            hdbscan_model=hdbscan_model,\n",
        "            vectorizer_model=vectorizer_model,\n",
        "            nr_topics=self.nr_topics,\n",
        "            calculate_probabilities=self.calculate_probabilities,\n",
        "            **self.bertopic_kwargs\n",
        "        )\n",
        "\n",
        "        # X is expected to be a pandas Series of preprocessed text\n",
        "        self.topics, self.probs = self.bertopic_model.fit_transform(X.tolist())\n",
        "        print(\"BERTopic model fitting complete.\")\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        if self.bertopic_model is None:\n",
        "            raise RuntimeError(\"BERTopic model not fitted. Call fit() first.\")\n",
        "        print(\"Transforming data with fitted BERTopic model...\")\n",
        "        topics, probs = self.bertopic_model.transform(X.tolist())\n",
        "        print(\"Transformation complete.\")\n",
        "        return topics # Return topic assignments\n",
        "\n",
        "    def get_model(self):\n",
        "        return self.bertopic_model\n",
        "\n",
        "# --- Utility function to display topics (adapted for both LDA and BERTopic) ---\n",
        "def display_topics(model, vectorizer=None, no_top_words=10, file=None):\n",
        "    \"\"\"\n",
        "    Prints or writes the top words for each topic.\n",
        "    Args:\n",
        "        model: The fitted topic model (LDA or BERTopic).\n",
        "        vectorizer (TfidfVectorizer, optional): The fitted TF-IDF vectorizer (for LDA).\n",
        "        no_top_words (int): The number of top words to display for each topic.\n",
        "        file (file object, optional): If provided, topics will be written to this file.\n",
        "        model_type (str): 'lda' or 'bertopic' to specify model type for appropriate display.\n",
        "    \"\"\"\n",
        "    topic_info = model.get_topic_info()\n",
        "    output_str = \"\\nBERTopic - Top Words per Topic:\\n\"\n",
        "    if file:\n",
        "        file.write(output_str)\n",
        "    else:\n",
        "        print(output_str)\n",
        "\n",
        "    # Iterate through all topics, excluding the noise topic (-1)\n",
        "    for topic_id in topic_info.Topic.unique():\n",
        "        if topic_id == -1: # Skip noise topic\n",
        "            continue\n",
        "        # Get the top words for the current topic\n",
        "        words = model.get_topic(topic_id)\n",
        "        if words:\n",
        "            top_words = \", \".join([word for word, _ in words[:no_top_words]])\n",
        "            topic_name = topic_info[topic_info['Topic'] == topic_id]['Name'].iloc[0]\n",
        "            output_str = f\"Topic {topic_id} ({topic_name}): {top_words}\\n\"\n",
        "            if file:\n",
        "                file.write(output_str)\n",
        "            else:\n",
        "                print(output_str)\n",
        "        else:\n",
        "            output_str = f\"Topic {topic_id}: No words found.\\n\"\n",
        "            if file:\n",
        "                file.write(output_str)\n",
        "            else:\n",
        "                print(output_str)\n",
        "\n",
        "\n",
        "# --- Main Topic Modeling Pipeline Class ---\n",
        "class TopicModelingPipeline:\n",
        "    def __init__(self, model_type='lda', **kwargs):\n",
        "        \"\"\"\n",
        "        Initializes the topic modeling pipeline.\n",
        "\n",
        "        Args:\n",
        "            model_type (str): The type of topic model to use ('lda' or 'bertopic').\n",
        "            **kwargs: Arguments specific to the chosen model or pipeline steps.\n",
        "                      For LDA: max_df, min_df, ngram_range (for TF-IDF), n_components, max_iter, etc.\n",
        "                      For BERTopic: embedding_model, umap_args, hdbscan_args, vectorizer_args, nr_topics, etc.\n",
        "        \"\"\"\n",
        "        self.model_type = model_type\n",
        "        self.pipeline = self._build_pipeline(**kwargs)\n",
        "\n",
        "    def _build_pipeline(self, **kwargs):\n",
        "        \"\"\"Builds the scikit-learn pipeline based on the specified model_type.\"\"\"\n",
        "        preprocessor_kwargs = {\n",
        "            'stop_words': kwargs.pop('stop_words', []),\n",
        "            'abbreviations': kwargs.pop('abbreviations', {})\n",
        "        }\n",
        "\n",
        "        pipeline_steps = [\n",
        "            ('preprocessor', TextPreprocessor(**preprocessor_kwargs))\n",
        "        ]\n",
        "\n",
        "        bertopic_kwargs = {\n",
        "            'embedding_model': kwargs.pop('embedding_model', 'all-MiniLM-L6-v2'),\n",
        "            'umap_args': kwargs.pop('umap_args', {}),\n",
        "            'hdbscan_args': kwargs.pop('hdbscan_args', {}),\n",
        "            'vectorizer_args': kwargs.pop('vectorizer_args', {}), # Pass custom vectorizer_args here\n",
        "            'nr_topics': kwargs.pop('nr_topics', \"auto\"),\n",
        "            'calculate_probabilities': kwargs.pop('calculate_probabilities', True),\n",
        "            **kwargs # Pass any remaining kwargs directly to BERTopicWrapper\n",
        "        }\n",
        "        pipeline_steps.append(('topic_modeler', BERTopicWrapper(**bertopic_kwargs)))\n",
        "\n",
        "        # Any remaining kwargs are ignored if not consumed by model-specific initializations\n",
        "        if kwargs:\n",
        "            print(f\"Warning: Unused keyword arguments passed to pipeline: {kwargs}\")\n",
        "\n",
        "        return Pipeline(pipeline_steps)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"Fits the entire pipeline to the input data.\"\"\"\n",
        "        print(f\"\\n--- Fitting {self.model_type.upper()} Topic Modeling Pipeline ---\")\n",
        "        self.pipeline.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Transforms the input data and returns topic assignments/distributions.\"\"\"\n",
        "        return self.pipeline.transform(X)\n",
        "\n",
        "    def get_topic_model(self):\n",
        "        \"\"\"Returns the underlying fitted topic model (LDA or BERTopic).\"\"\"\n",
        "        return self.pipeline.named_steps['topic_modeler'].get_model()\n",
        "\n",
        "    def get_vectorizer(self):\n",
        "        \"\"\"Returns the fitted vectorizer (TF-IDF for LDA, None for BERTopic).\"\"\"\n",
        "        if self.model_type == 'lda':\n",
        "            return self.pipeline.named_steps['tfidf_vectorizer']\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hdbscan import HDBSCAN\n",
        "\n",
        "output_dir = \"data/temp/leslie_topic_modelling_fine_tuning\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "no_top_words = 10\n",
        "bertopic_pipeline_instance = TopicModelingPipeline(\n",
        "    embedding_model='all-MiniLM-L6-v2',\n",
        "    model_type='bertopic',\n",
        "    nr_topics=8,\n",
        "    calculate_probabilities=True,\n",
        "    # umap_args={'n_neighbors': 15, 'n_components': 5},\n",
        "    vectorizer_args={'min_df': 1},\n",
        "    stop_words=gs_stopwords,\n",
        "    abbreviations=abbreviations\n",
        ")\n",
        "bertopic_pipeline_instance.fit(grouped_gs_qna_df['content'])\n",
        "bertopic_model = bertopic_pipeline_instance.get_topic_model()\n",
        "\n",
        "output_filename_bertopic = f\"{output_dir}/bertopic_topics.txt\"\n",
        "with open(output_filename_bertopic, 'w', encoding='utf-8') as f:\n",
        "    f.write(\"--- BERTopic Model ---\\n\\n\")\n",
        "    f.write(\"Interpreting Topics:\\n\")\n",
        "    display_topics(bertopic_model, no_top_words=no_top_words, file=f)\n",
        "print(f\"BERTopic Topics saved to {output_filename_bertopic}\")\n",
        "\n",
        "# Assign dominant topics for BERTopic\n",
        "bertopic_topic_assignments = bertopic_pipeline_instance.transform(grouped_gs_qna_df['content'])\n",
        "grouped_gs_qna_df['dominant_topic_bertopic'] = bertopic_topic_assignments\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94HKBhKS-OWL",
        "outputId": "02af0c81-f152-4712-976b-2265f084efcc"
      },
      "id": "94HKBhKS-OWL",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fitting BERTOPIC Topic Modeling Pipeline ---\n",
            "Starting Phase 1: Preprocessing...\n",
            "Preprocessing complete.\n",
            "\n",
            "Starting Phase 3: Topic Modeling (BERTopic)...\n",
            "BERTopic model fitting complete.\n",
            "BERTopic Topics saved to data/temp/leslie_topic_modelling_fine_tuning/bertopic_topics.txt\n",
            "Starting Phase 1: Preprocessing...\n",
            "Preprocessing complete.\n",
            "Transforming data with fitted BERTopic model...\n",
            "Transformation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bertopic_model.get_topic_info()"
      ],
      "metadata": {
        "id": "EmBwa_8SGNdY",
        "outputId": "b2022bda-ea13-4176-9315-11cafb2c793b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "id": "EmBwa_8SGNdY",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Topic  Count                           Name  \\\n",
              "0     -1     64    -1_client_thing_term_market   \n",
              "1      0     11  0_term_fee_alternative_growth   \n",
              "2      1     74    1_client_market_give_growth   \n",
              "\n",
              "                                      Representation  \\\n",
              "0  [client, thing, term, market, growth, rm, pla...   \n",
              "1  [term, fee, alternative, growth, alt, fundrais...   \n",
              "2  [client, market, give, growth, thing, business...   \n",
              "\n",
              "                                 Representative_Docs  \n",
              "0  [get question consumer pivot , break . let add...  \n",
              "1  [, great . , david dennis . couple question aw...  \n",
              "2  [. .   , betsy .   . make platform solution . ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba7834aa-67ed-49a1-9f6c-e09d9a821ea1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Count</th>\n",
              "      <th>Name</th>\n",
              "      <th>Representation</th>\n",
              "      <th>Representative_Docs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>64</td>\n",
              "      <td>-1_client_thing_term_market</td>\n",
              "      <td>[client, thing, term, market, growth, rm, pla...</td>\n",
              "      <td>[get question consumer pivot , break . let add...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0_term_fee_alternative_growth</td>\n",
              "      <td>[term, fee, alternative, growth, alt, fundrais...</td>\n",
              "      <td>[, great . , david dennis . couple question aw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>74</td>\n",
              "      <td>1_client_market_give_growth</td>\n",
              "      <td>[client, market, give, growth, thing, business...</td>\n",
              "      <td>[. .   , betsy .   . make platform solution . ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba7834aa-67ed-49a1-9f6c-e09d9a821ea1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ba7834aa-67ed-49a1-9f6c-e09d9a821ea1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ba7834aa-67ed-49a1-9f6c-e09d9a821ea1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-35d8a251-523a-4dbf-a48d-4537c799b767\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35d8a251-523a-4dbf-a48d-4537c799b767')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-35d8a251-523a-4dbf-a48d-4537c799b767 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"bertopic_model\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Topic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": -1,\n        \"max\": 1,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -1,\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33,\n        \"min\": 11,\n        \"max\": 74,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          64,\n          11,\n          74\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"-1_client_thing_term_market\",\n          \"0_term_fee_alternative_growth\",\n          \"1_client_market_give_growth\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Representation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Representative_Docs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9889a4cc",
      "metadata": {
        "id": "9889a4cc"
      },
      "source": [
        "Conclusion and Recommendation\n",
        "The addition of stopwords has certainly helped in some areas, making certain topics clearer. However, some conversational noise still persists, especially words related to the Q&A format or general conversational patterns. The term \"Apple\" continues to be grouped with \"deposit\" in some k values, which is still a bit puzzling without specific context.\n",
        "\n",
        "Based on this comprehensive analysis, the most sensible k value is a trade-off between granularity, coherence, and minimizing \"junk\" topics.\n",
        "\n",
        "k=8: Offers good clarity for key themes (Credit Card, Headcount/Severance, Asset/Fundraising), but is still quite broad and has some remaining conversational noise.\n",
        "k=9: Introduces very strong \"GSIB\" and \"Wealth Management\" topics.\n",
        "k=10: Shows strong \"Investment/Platform\" and \"Fundraising\" themes.\n",
        "k=11: This k value demonstrates the best balance in this new set of runs.\n",
        "It produces several very distinct and interpretable financial/business topics: \"Wealth Management/European Footprint\" , \"Severance/Headcount/Capital\" , \"Credit Card/Consumer\" , \"GSIB/Allocation\" , \"Bank/Acquisition/Advisory\" , \"FICC/Equity/Commodity\" , and \"Deposit/Capital/Market/Exposure\".\n",
        "\n",
        "Crucially, the \"Apple\" anomaly is not present in the top words of any topic for k=11, suggesting a cleaner separation of terms.\n",
        "While some conversational noise is still present (Topics 2, 4, 9 in k=11), the quality of the interpretable topics is high.\n",
        "k=12, k=13, k=14: Beyond k=11, the topics generally become more fragmented, or reintroduce the \"Apple\" anomaly, and the number of less coherent/conversational topics increases, making overall interpretation more challenging. For example, k=12 recombines \"funding/deposits\" with \"severance/headcount\", which is less ideal.\n",
        "Therefore, my strongest recommendation is k=11. It provides a good level of detail for key financial aspects of Goldman Sachs' earnings calls while offering significantly improved topic coherence and distinctiveness, and effectively mitigating some of the persistent noise terms seen in other k values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8108189b",
      "metadata": {
        "id": "8108189b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "topic_labels_map = {\n",
        "    0: \"Strategic Positioning & Platform\",\n",
        "    1: \"Wealth Management & European Markets\",\n",
        "    2: \"Alternative Investments & Fee Income\",\n",
        "    3: \"Headcount & Workforce Management\",\n",
        "    4: \"Consumer Credit & Card Performance\",\n",
        "    5: \"FICC & Equity Trading Performance\",\n",
        "    6: \"Regulatory Capital & Institutional Allocation\",\n",
        "    7: \"Client-Centric Growth & Solutions\",\n",
        "    8: \"M&A, Valuations & Advisory\",\n",
        "    9: \"FICC & Market Environment\",\n",
        "    10: \"Deposits, Capital & Funding\"\n",
        "}\n",
        "\n",
        "# Assign labels to the topics_data\n",
        "for topic_info in topics_data:\n",
        "    topic_info['label'] = topic_labels_map.get(topic_info['topic_idx'], f\"Unlabeled Topic {topic_info['topic_idx']}\")\n",
        "\n",
        "print(\"\\n--- Topics with assigned labels and top words ---\")\n",
        "for topic_info in topics_data:\n",
        "    print(f\"Topic {topic_info['topic_idx'] + 1}: {topic_info['label']}\")\n",
        "    print(f\"  Top Words: {' '.join(topic_info['top_words'])}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# --- Visual Display of Topics ---\n",
        "print(\"\\n--- Generating visual display of topics ---\")\n",
        "\n",
        "n_cols = 3\n",
        "n_rows = (num_topics + n_cols - 1) // n_cols\n",
        "plt.figure(figsize=(n_cols * 6, n_rows * 4), dpi=100)\n",
        "\n",
        "for i, topic_info in enumerate(topics_data):\n",
        "    ax = plt.subplot(n_rows, n_cols, i + 1)\n",
        "    df_plot = pd.DataFrame({\n",
        "        'word': topic_info['top_words'],\n",
        "        'weight': topic_info['word_weights']\n",
        "    })\n",
        "    df_plot = df_plot.sort_values(by='weight', ascending=True)\n",
        "    sns.barplot(x='weight', y='word', data=df_plot, palette='magma', ax=ax)\n",
        "    ax.set_title(f\"{topic_info['label']}\", fontsize=11, fontweight='bold', pad=10)\n",
        "    ax.set_xlabel(\"Word Importance (Weight)\", fontsize=9)\n",
        "    ax.set_ylabel(\"\")\n",
        "    ax.tick_params(axis='both', which='major', labelsize=8)\n",
        "    sns.despine(ax=ax, top=True, right=True, left=False, bottom=False)\n",
        "    ax.tick_params(axis='y', length=0)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "plt.suptitle(\n",
        "    f\"Top Words for {num_topics} Topics in Goldman Sachs Earnings Calls (Q&A Section)\",\n",
        "    y=1.00, fontsize=16, fontweight='bold'\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nVisual display generated. Please review the plots and verify the topic labels.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f760200",
      "metadata": {
        "id": "7f760200"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "959f9349",
      "metadata": {
        "id": "959f9349"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(\n",
        "    data=grouped_gs_qna_df,\n",
        "    x='year',\n",
        "    hue='quarter',\n",
        "    palette='tab10'\n",
        ")\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Documents')\n",
        "plt.title('Distribution of Documents by Year and Quarter\\nGoldman Sachs Q&A')\n",
        "plt.legend(title='Quarter')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Now, for dominant topics over both year and quarter:\n",
        "plt.figure(figsize=(16, 7))\n",
        "sns.countplot(\n",
        "    data=grouped_gs_qna_df,\n",
        "    x='dominant_topic_k11',\n",
        "    hue='year',\n",
        "    palette='tab10'\n",
        ")\n",
        "topic_labels = [topic_labels_map.get(i, f\"Topic {i}\") for i in sorted(grouped_gs_qna_df['dominant_topic_k11'].unique())]\n",
        "plt.xticks(ticks=range(len(topic_labels)), labels=topic_labels, rotation=45, ha='right')\n",
        "plt.xlabel('Dominant Topic (k=11)')\n",
        "plt.ylabel('Number of Documents')\n",
        "plt.title('Dominant Topics (k=11) by Year\\nGoldman Sachs Q&A')\n",
        "plt.legend(title='Year')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e53850b",
      "metadata": {
        "id": "6e53850b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "years = sorted(grouped_gs_qna_df['year'].unique())\n",
        "n_years = len(years)\n",
        "\n",
        "fig, axes = plt.subplots(n_years, 1, figsize=(10, 4 * n_years), sharex=True)\n",
        "\n",
        "if n_years == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for idx, year in enumerate(years):\n",
        "    ax = axes[idx]\n",
        "    data = grouped_gs_qna_df[grouped_gs_qna_df['year'] == year]\n",
        "    sns.countplot(\n",
        "        data=data,\n",
        "        x='quarter',\n",
        "        hue='dominant_topic_k11',\n",
        "        palette='tab10',\n",
        "        ax=ax\n",
        "    )\n",
        "    ax.set_title(f'Distribution of Dominant Topics (k=11) by Quarter - {year}')\n",
        "    ax.set_xlabel('Quarter')\n",
        "    ax.set_ylabel('Number of Documents')\n",
        "    ax.legend(\n",
        "        title='Dominant Topic',\n",
        "        loc='upper right',\n",
        "        labels=[topic_labels_map.get(i, f\"Topic {i}\") for i in sorted(data['dominant_topic_k11'].unique())]\n",
        "    )\n",
        "\n",
        "# Fix color mapping so each topic always has the same color across years\n",
        "unique_topics = sorted(grouped_gs_qna_df['dominant_topic_k11'].unique())\n",
        "topic_palette = sns.color_palette('tab10', n_colors=len(unique_topics))\n",
        "topic_color_dict = {topic: topic_palette[i % len(topic_palette)] for i, topic in enumerate(unique_topics)}\n",
        "\n",
        "for idx, year in enumerate(years):\n",
        "    ax = axes[idx]\n",
        "    data = grouped_gs_qna_df[grouped_gs_qna_df['year'] == year]\n",
        "    # Use the same color mapping for all years\n",
        "    sns.countplot(\n",
        "        data=data,\n",
        "        x='quarter',\n",
        "        hue='dominant_topic_k11',\n",
        "        palette=topic_color_dict,\n",
        "        ax=ax\n",
        "    )\n",
        "    ax.set_title(f'Distribution of Dominant Topics (k=11) by Quarter - {year}')\n",
        "    ax.set_xlabel('Quarter')\n",
        "    ax.set_ylabel('Number of Documents')\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    # Always use the same order and labels for legend\n",
        "    ordered_labels = [topic_labels_map.get(t, f\"Topic {t}\") for t in unique_topics]\n",
        "    ax.legend(handles, ordered_labels, title='Dominant Topic', loc='upper right')\n",
        "\n",
        "plt.suptitle(\n",
        "    \"Quarterly Distribution of Dominant Topics (k=11) by Year\\nGoldman Sachs Earnings Call Transcript (Q&A Section)\",\n",
        "    fontsize=16, fontweight='bold', y=1.02\n",
        ")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7817bea",
      "metadata": {
        "id": "f7817bea"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8f10d7a1",
      "metadata": {
        "id": "8f10d7a1"
      },
      "source": [
        "# Save Data Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb15dc4f",
      "metadata": {
        "id": "bb15dc4f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "target_dir = 'data/temp/'\n",
        "file_name = 'dummy_test_output_new.csv'\n",
        "dummy_pf = pd.DataFrame({'from_colab': [IS_COLAB, True, 'hello']})\n",
        "\n",
        "\n",
        "if OUTPUT_PROCESSED_FILES:\n",
        "    if IS_COLAB:\n",
        "        AUTHENTICATED_REPO_URL = REPO_URL.replace(\"https://\", f\"https://{GITHUB_USERNAME}:{GITHUB_TOKEN}@\")\n",
        "        dummy_pf.to_csv(f\"{target_dir}{file_name}\", index=False)\n",
        "\n",
        "        # Configure Git user (important for committing)\n",
        "        !git config user.email \"{GITHUB_EMAIL}\"\n",
        "        !git config user.name \"{GITHUB_USERNAME}\"\n",
        "        !git remote set-url origin {AUTHENTICATED_REPO_URL}\n",
        "\n",
        "        # Add the file to staging\n",
        "        !git add {target_dir}{file_name}\n",
        "        print(f\"Added '{target_dir}{file_name}' to staging.\")\n",
        "\n",
        "        # Commit the changes\n",
        "        commit_message = f\"Add new data file: {target_dir}{file_name}\"\n",
        "        !git commit -m \"{commit_message}\"\n",
        "        print(f\"Committed changes with message: '{commit_message}'\")\n",
        "        print(f\"Attempted commit with message: '{commit_message}'\")\n",
        "\n",
        "        # Add this line to debug:\n",
        "        print(f\"Value of REPO_BRANCH before push: {REPO_BRANCH}\")\n",
        "\n",
        "        print(\"Pushing changes to GitHub. Please enter your GitHub username and Personal Access Token when prompted.\")\n",
        "        !git push --set-upstream origin {REPO_BRANCH} --force\n",
        "        print(\"Push command executed. Check output for success or prompt.\")\n",
        "    else:\n",
        "        dummy_pf.to_csv(f\"{target_dir}{file_name}\", index=False)\n",
        "        print(\"Processed files saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QAa-7pTX73f4",
      "metadata": {
        "id": "QAa-7pTX73f4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0rc2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}