{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3390045b",
      "metadata": {
        "id": "3390045b"
      },
      "source": [
        "# Setup, Constants, and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "70ea4469",
      "metadata": {
        "id": "70ea4469"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import logging"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd643fb0",
      "metadata": {
        "id": "fd643fb0"
      },
      "source": [
        "## Notebook Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3c08565b",
      "metadata": {
        "id": "3c08565b"
      },
      "outputs": [],
      "source": [
        "IS_COLAB = 'google.colab' in sys.modules\n",
        "OUTPUT_PROCESSED_FILES = False # TODO: Use this if you want to output save files (optional - see below)\n",
        "\n",
        "if IS_COLAB:\n",
        "    from google.colab import userdata\n",
        "    GITHUB_USERNAME = userdata.get('github_user')\n",
        "    GITHUB_TOKEN = userdata.get('github_token')\n",
        "    GITHUB_EMAIL = userdata.get('github_email')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd9d4e41",
      "metadata": {
        "id": "cd9d4e41"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5129180d",
      "metadata": {
        "id": "5129180d"
      },
      "outputs": [],
      "source": [
        "REPO_URL = \"https://github.com/EErlando/Quarterly-Bytes.git\"\n",
        "REPO_NAME = \"src\"\n",
        "REPO_BRANCH = \"LP_topic_modelling_extended\" # TODO: UPDATE THIS TO YOU BRANCH - DEFAULT TO MAIN\n",
        "NOTEBOOK_DIR = \"3_modelling\" # TODO: UPDATE THIS TO YOUR NOTEBOOK DIRECTORY (e.g. 1_data_extraction_and_processing)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0864529e",
      "metadata": {
        "id": "0864529e"
      },
      "source": [
        "## Clone and Pull Latest from Repository - Colab Specific"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "91c87440",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91c87440",
        "outputId": "d53ffe0f-ecaf-4f8c-9035-7d547bb08afa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'src' already exists. Pulling latest changes...\n",
            "/content/src/src\n",
            "/content/src\n",
            "/content/src\n",
            "Requirement already satisfied: PyPDF2==3.0.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (3.0.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.6.1)\n",
            "Requirement already satisfied: nltk>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (3.9.1)\n",
            "Requirement already satisfied: spacy>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.8.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.13.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (4.52.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (2.0.2)\n",
            "Requirement already satisfied: bertopic in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (0.17.0)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.5.7)\n",
            "Requirement already satisfied: python-dev-tools in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (2023.3.24)\n",
            "Requirement already satisfied: hdbscan==0.8.40 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (0.8.40)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (4.1.0)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan==0.8.40->-r requirements.txt (line 15)) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan==0.8.40->-r requirements.txt (line 15)) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.0->-r requirements.txt (line 4)) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.0->-r requirements.txt (line 4)) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.0.0->-r requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (0.16.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.0.0->-r requirements.txt (line 5)) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 6)) (3.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 9)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 9)) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 10)) (0.33.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 10)) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 10)) (0.5.3)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from bertopic->-r requirements.txt (line 12)) (5.24.1)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn->-r requirements.txt (line 13)) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn->-r requirements.txt (line 13)) (0.5.13)\n",
            "Requirement already satisfied: Sphinx<7,>=6 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (6.2.1)\n",
            "Requirement already satisfied: autoflake<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.7.8)\n",
            "Requirement already satisfied: black<24,>=23 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (23.12.1)\n",
            "Requirement already satisfied: coverage[toml]<8,>=7 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (7.9.1)\n",
            "Requirement already satisfied: darglint<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.8.1)\n",
            "Requirement already satisfied: dlint<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.16.0)\n",
            "Requirement already satisfied: doc8<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.1.2)\n",
            "Requirement already satisfied: docformatter<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.7.7)\n",
            "Requirement already satisfied: flake8<6,>=5 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (5.0.4)\n",
            "Requirement already satisfied: flake8-2020<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.8.1)\n",
            "Requirement already satisfied: flake8-aaa<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.17.0)\n",
            "Requirement already satisfied: flake8-annotations<4,>=3 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (3.1.1)\n",
            "Requirement already satisfied: flake8-annotations-complexity<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.1.0)\n",
            "Requirement already satisfied: flake8-annotations-coverage<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.0.6)\n",
            "Requirement already satisfied: flake8-bandit<5,>=4 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (4.1.1)\n",
            "Requirement already satisfied: flake8-black<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.3.6)\n",
            "Requirement already satisfied: flake8-blind-except<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.2.1)\n",
            "Requirement already satisfied: flake8-breakpoint<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.1.0)\n",
            "Requirement already satisfied: flake8-broken-line<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.6.0)\n",
            "Requirement already satisfied: flake8-bugbear<24,>=23 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (23.3.12)\n",
            "Requirement already satisfied: flake8-builtins<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.5.3)\n",
            "Requirement already satisfied: flake8-class-attributes-order<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.3.0)\n",
            "Requirement already satisfied: flake8-coding<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.3.2)\n",
            "Requirement already satisfied: flake8-cognitive-complexity<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.1.0)\n",
            "Requirement already satisfied: flake8-comments<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.1.2)\n",
            "Requirement already satisfied: flake8-comprehensions<4,>=3 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (3.16.0)\n",
            "Requirement already satisfied: flake8-debugger<5,>=4 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (4.1.2)\n",
            "Requirement already satisfied: flake8-django<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.4)\n",
            "Requirement already satisfied: flake8-docstrings<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.7.0)\n",
            "Requirement already satisfied: flake8-encodings<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.5.1)\n",
            "Requirement already satisfied: flake8-eradicate<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.5.0)\n",
            "Requirement already satisfied: flake8-executable<3,>=2 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (2.1.3)\n",
            "Requirement already satisfied: flake8-expression-complexity<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.0.11)\n",
            "Requirement already satisfied: flake8-fastapi<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.7.0)\n",
            "Requirement already satisfied: flake8-fixme<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.1.1)\n",
            "Requirement already satisfied: flake8-functions<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.0.8)\n",
            "Requirement already satisfied: flake8-functions-names<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.4.0)\n",
            "Requirement already satisfied: flake8-future-annotations<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.0.5)\n",
            "Requirement already satisfied: flake8-isort<7,>=6 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (6.1.2)\n",
            "Requirement already satisfied: flake8-literal<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.4.0)\n",
            "Requirement already satisfied: flake8-logging-format<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.9.0)\n",
            "Requirement already satisfied: flake8-markdown<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.6.0)\n",
            "Requirement already satisfied: flake8-mutable<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.2.0)\n",
            "Requirement already satisfied: flake8-no-pep420<3,>=2 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (2.8.0)\n",
            "Requirement already satisfied: flake8-noqa<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.4.0)\n",
            "Requirement already satisfied: flake8-pie<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.16.0)\n",
            "Requirement already satisfied: flake8-pyi<23,>=22 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (22.11.0)\n",
            "Requirement already satisfied: flake8-pylint<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.2.1)\n",
            "Requirement already satisfied: flake8-pytest-style<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.7.2)\n",
            "Requirement already satisfied: flake8-quotes<4,>=3 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (3.4.0)\n",
            "Requirement already satisfied: flake8-rst-docstrings<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.3.1)\n",
            "Requirement already satisfied: flake8-secure-coding-standard<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.4.1)\n",
            "Requirement already satisfied: flake8-simplify<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.22.0)\n",
            "Requirement already satisfied: flake8-string-format<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.3.0)\n",
            "Requirement already satisfied: flake8-tidy-imports<5,>=4 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (4.11.0)\n",
            "Requirement already satisfied: flake8-typing-imports<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.16.0)\n",
            "Requirement already satisfied: flake8-use-fstring<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.4)\n",
            "Requirement already satisfied: flake8-use-pathlib<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.3.0)\n",
            "Requirement already satisfied: flake8-useless-assert<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.4.4)\n",
            "Requirement already satisfied: flake8-variables-names<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.0.6)\n",
            "Requirement already satisfied: flake8-warnings<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.4.0)\n",
            "Requirement already satisfied: jupyterlab-flake8<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.7.1)\n",
            "Requirement already satisfied: pandas-vet<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.2.3)\n",
            "Requirement already satisfied: pep8-naming<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.15.1)\n",
            "Requirement already satisfied: pip<23,>=22 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (22.3.1)\n",
            "Requirement already satisfied: pybetter<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.4.1)\n",
            "Requirement already satisfied: pycln<3,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (2.5.0)\n",
            "Requirement already satisfied: pycodestyle<3,>=2 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (2.9.1)\n",
            "Requirement already satisfied: pydocstyle<7,>=6 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (6.3.0)\n",
            "Requirement already satisfied: pytest<8,>=7 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (7.4.4)\n",
            "Requirement already satisfied: pytest-cov<5,>=4 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (4.1.0)\n",
            "Requirement already satisfied: pytest-sugar<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.9.7)\n",
            "Requirement already satisfied: pyupgrade<4,>=3 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (3.20.0)\n",
            "Requirement already satisfied: removestar<2,>=1 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (1.5.2)\n",
            "Requirement already satisfied: ssort<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.14.0)\n",
            "Requirement already satisfied: tox<5,>=4 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (4.27.0)\n",
            "Requirement already satisfied: tox-travis<1,>=0 in /usr/local/lib/python3.11/dist-packages (from python-dev-tools->-r requirements.txt (line 14)) (0.12)\n",
            "Requirement already satisfied: pyflakes<3,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from autoflake<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (2.5.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from black<24,>=23->python-dev-tools->-r requirements.txt (line 14)) (1.1.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from black<24,>=23->python-dev-tools->-r requirements.txt (line 14)) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black<24,>=23->python-dev-tools->-r requirements.txt (line 14)) (4.3.8)\n",
            "Requirement already satisfied: docutils<=0.21.2,>=0.19 in /usr/local/lib/python3.11/dist-packages (from doc8<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (0.19)\n",
            "Requirement already satisfied: restructuredtext-lint>=0.7 in /usr/local/lib/python3.11/dist-packages (from doc8<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (1.4.0)\n",
            "Requirement already satisfied: stevedore in /usr/local/lib/python3.11/dist-packages (from doc8<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (5.4.1)\n",
            "Requirement already satisfied: Pygments in /usr/local/lib/python3.11/dist-packages (from doc8<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (2.19.1)\n",
            "Requirement already satisfied: charset_normalizer<4.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from docformatter<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (3.4.2)\n",
            "Requirement already satisfied: untokenize<0.2.0,>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from docformatter<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (0.1.1)\n",
            "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from flake8<6,>=5->python-dev-tools->-r requirements.txt (line 14)) (0.7.0)\n",
            "Requirement already satisfied: asttokens>=2 in /usr/local/lib/python3.11/dist-packages (from flake8-aaa<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (3.0.0)\n",
            "Requirement already satisfied: attrs>=21.4 in /usr/local/lib/python3.11/dist-packages (from flake8-annotations<4,>=3->python-dev-tools->-r requirements.txt (line 14)) (25.3.0)\n",
            "Requirement already satisfied: bandit>=1.7.3 in /usr/local/lib/python3.11/dist-packages (from flake8-bandit<5,>=4->python-dev-tools->-r requirements.txt (line 14)) (1.8.5)\n",
            "Requirement already satisfied: flake8-plugin-utils<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from flake8-breakpoint<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (1.3.3)\n",
            "Requirement already satisfied: cognitive-complexity in /usr/local/lib/python3.11/dist-packages (from flake8-cognitive-complexity<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (1.3.0)\n",
            "Requirement already satisfied: astroid<3.0.0,>=2.15.2 in /usr/local/lib/python3.11/dist-packages (from flake8-django<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (2.15.8)\n",
            "Requirement already satisfied: astatine>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from flake8-encodings<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.3.3)\n",
            "Requirement already satisfied: domdf-python-tools>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from flake8-encodings<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (3.10.0)\n",
            "Requirement already satisfied: flake8-helper>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from flake8-encodings<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.2.2)\n",
            "Requirement already satisfied: eradicate<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from flake8-eradicate<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (2.3.0)\n",
            "Requirement already satisfied: astpretty in /usr/local/lib/python3.11/dist-packages (from flake8-expression-complexity<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (3.0.0)\n",
            "Requirement already satisfied: fastapi>=0.65.1 in /usr/local/lib/python3.11/dist-packages (from flake8-fastapi<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.115.12)\n",
            "Requirement already satisfied: mr-proper in /usr/local/lib/python3.11/dist-packages (from flake8-functions<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.0.7)\n",
            "Requirement already satisfied: isort<7,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from flake8-isort<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (5.13.2)\n",
            "Requirement already satisfied: pylint in /usr/local/lib/python3.11/dist-packages (from flake8-pylint<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (2.17.7)\n",
            "Requirement already satisfied: astor>=0.1 in /usr/local/lib/python3.11/dist-packages (from flake8-simplify<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.8.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->-r requirements.txt (line 10)) (1.1.3)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.0.0->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn->-r requirements.txt (line 13)) (0.43.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic->-r requirements.txt (line 12)) (9.1.2)\n",
            "Requirement already satisfied: hypothesmith<0.2.0,>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from pybetter<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.1.9)\n",
            "Requirement already satisfied: libcst<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from pybetter<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.4.10)\n",
            "Requirement already satisfied: pyemojify<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from pybetter<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.2.0)\n",
            "Requirement already satisfied: tomlkit>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from pycln<3,>=1->python-dev-tools->-r requirements.txt (line 14)) (0.13.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.0->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.0->-r requirements.txt (line 5)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.0->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: snowballstemmer>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pydocstyle<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (3.0.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest<8,>=7->python-dev-tools->-r requirements.txt (line 14)) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from pytest<8,>=7->python-dev-tools->-r requirements.txt (line 14)) (1.6.0)\n",
            "Requirement already satisfied: termcolor>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytest-sugar<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 2)) (1.17.0)\n",
            "Requirement already satisfied: tokenize-rt>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from pyupgrade<4,>=3->python-dev-tools->-r requirements.txt (line 14)) (6.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->-r requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->-r requirements.txt (line 5)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->-r requirements.txt (line 5)) (2025.6.15)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.11/dist-packages (from Sphinx<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.11/dist-packages (from Sphinx<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.11/dist-packages (from Sphinx<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from Sphinx<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from Sphinx<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.11/dist-packages (from Sphinx<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (2.0.0)\n",
            "Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.11/dist-packages (from Sphinx<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (2.17.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.11/dist-packages (from Sphinx<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (0.7.16)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from Sphinx<7,>=6->python-dev-tools->-r requirements.txt (line 14)) (1.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy>=3.0.0->-r requirements.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.0.0->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.0.0->-r requirements.txt (line 5)) (0.1.5)\n",
            "Requirement already satisfied: cachetools>=5.5.1 in /usr/local/lib/python3.11/dist-packages (from tox<5,>=4->python-dev-tools->-r requirements.txt (line 14)) (5.5.2)\n",
            "Requirement already satisfied: chardet>=5.2 in /usr/local/lib/python3.11/dist-packages (from tox<5,>=4->python-dev-tools->-r requirements.txt (line 14)) (5.2.0)\n",
            "Requirement already satisfied: colorama>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from tox<5,>=4->python-dev-tools->-r requirements.txt (line 14)) (0.4.6)\n",
            "Requirement already satisfied: pyproject-api>=1.8 in /usr/local/lib/python3.11/dist-packages (from tox<5,>=4->python-dev-tools->-r requirements.txt (line 14)) (1.9.1)\n",
            "Requirement already satisfied: virtualenv>=20.31 in /usr/local/lib/python3.11/dist-packages (from tox<5,>=4->python-dev-tools->-r requirements.txt (line 14)) (20.31.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.0.0->-r requirements.txt (line 5)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.0.0->-r requirements.txt (line 5)) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.0.0->-r requirements.txt (line 5)) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.0.0->-r requirements.txt (line 5)) (7.1.0)\n",
            "Requirement already satisfied: lazy-object-proxy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from astroid<3.0.0,>=2.15.2->flake8-django<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (1.11.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.14 in /usr/local/lib/python3.11/dist-packages (from astroid<3.0.0,>=2.15.2->flake8-django<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (1.17.2)\n",
            "Requirement already satisfied: natsort>=7.0.1 in /usr/local/lib/python3.11/dist-packages (from domdf-python-tools>=2.8.1->flake8-encodings<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (8.4.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.65.1->flake8-fastapi<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.46.2)\n",
            "Requirement already satisfied: hypothesis>=5.41.0 in /usr/local/lib/python3.11/dist-packages (from hypothesmith<0.2.0,>=0.1.8->pybetter<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (6.135.11)\n",
            "Requirement already satisfied: lark-parser>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from hypothesmith<0.2.0,>=0.1.8->pybetter<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.12.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.0.0->-r requirements.txt (line 5)) (1.2.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from libcst<0.5.0,>=0.4.1->pybetter<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.9.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.0.0->-r requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore->doc8<2,>=1->python-dev-tools->-r requirements.txt (line 14)) (6.1.1)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.31->tox<5,>=4->python-dev-tools->-r requirements.txt (line 14)) (0.3.9)\n",
            "Requirement already satisfied: stdlib-list>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from mr-proper->flake8-functions<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.11.1)\n",
            "Requirement already satisfied: dill>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from pylint->flake8-pylint<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (0.3.7)\n",
            "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from hypothesis>=5.41.0->hypothesmith<0.2.0,>=0.1.8->pybetter<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.0.0->-r requirements.txt (line 5)) (0.1.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi>=0.65.1->flake8-fastapi<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (4.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi>=0.65.1->flake8-fastapi<1,>=0->python-dev-tools->-r requirements.txt (line 14)) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "if IS_COLAB:\n",
        "    !git config pull.rebase false\n",
        "    if os.path.exists(REPO_NAME):\n",
        "        print(f\"Directory '{REPO_NAME}' already exists. Pulling latest changes...\")\n",
        "        %cd {REPO_NAME}\n",
        "        !git pull origin {REPO_BRANCH} --quiet\n",
        "        %cd ..\n",
        "    else:\n",
        "        print(f\"Cloning repository into '{REPO_NAME}'...\")\n",
        "        !git clone --quiet --branch {REPO_BRANCH} {REPO_URL} {REPO_NAME}\n",
        "        print(\"Clone complete.\")\n",
        "\n",
        "    sys.path.append('/content/src/')\n",
        "    %cd /content/src/\n",
        "    !pip install -r requirements.txt\n",
        "else:\n",
        "    if os.path.basename(os.getcwd()) == NOTEBOOK_DIR:\n",
        "        os.chdir('../../') # TODO: UPDATE THIS TO ROOT OF REPO\n",
        "\n",
        "    !pip install -r requirements.txt\n",
        "\n",
        "logging.basicConfig(level=logging.ERROR, format='%(levelname)s: %(message)s')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post Install Imports"
      ],
      "metadata": {
        "id": "ryvB1Hpx1C3V"
      },
      "id": "ryvB1Hpx1C3V"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "import os\n",
        "!pip install bertopic\n",
        "\n",
        "from bertopic import BERTopic\n"
      ],
      "metadata": {
        "id": "x4EyBg8j1FgP",
        "outputId": "afd85606-679f-45c5-b7c8-27acb86218a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "x4EyBg8j1FgP",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bertopic in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
            "Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.8.40)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from bertopic) (2.2.2)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (5.24.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from bertopic) (4.1.0)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.11/dist-packages (from bertopic) (4.67.1)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.5.7)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (25.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->bertopic) (3.6.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.52.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.33.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.14.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (1.1.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "02d72bb0",
      "metadata": {
        "id": "02d72bb0",
        "outputId": "98cf0aba-b03e-423f-fe5e-1e8c38cdb5b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6147c7a",
      "metadata": {
        "id": "c6147c7a"
      },
      "source": [
        "## Local Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f2963e1f",
      "metadata": {
        "id": "f2963e1f"
      },
      "outputs": [],
      "source": [
        "from src.utils.common_helpers import read_yaml_file, read_list_from_text_file"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2569d135",
      "metadata": {
        "id": "2569d135"
      },
      "source": [
        "## Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a60bdaad",
      "metadata": {
        "id": "a60bdaad"
      },
      "outputs": [],
      "source": [
        "def group_df(df, group_by_columns, agg_column='content'):\n",
        "    \"\"\"\n",
        "    Groups the DataFrame by specified columns and aggregates the content column.\n",
        "\n",
        "    Parameters:\n",
        "    - df: DataFrame to group\n",
        "    - group_by_columns: List of columns to group by\n",
        "    - agg_column: Column to aggregate (default is 'content')\n",
        "\n",
        "    Returns:\n",
        "    - Grouped DataFrame with aggregated content\n",
        "    \"\"\"\n",
        "    return df.groupby(group_by_columns, as_index=False).agg({agg_column: ' '.join})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62b50738",
      "metadata": {
        "id": "62b50738"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4f87c1ff",
      "metadata": {
        "id": "4f87c1ff"
      },
      "outputs": [],
      "source": [
        "gs_discussion_df = pd.read_csv('data/processed/Goldman Sachs/discussion_df.csv')\n",
        "gs_qna_df = pd.read_csv('data/processed/Goldman Sachs/qna_df.csv')\n",
        "jp_discussion_df = pd.read_csv('data/processed/JP Morgan/discussion_df.csv')\n",
        "jp_qna_df = pd.read_csv('data/processed/JP Morgan/qna_df.csv')\n",
        "\n",
        "\n",
        "# Goldman Sachs\n",
        "grouped_gs_discussion_df = group_df(gs_discussion_df, ['quarter', 'year'])\n",
        "grouped_gs_qna_df = group_df(gs_qna_df, ['question_answer_group_id', 'quarter', 'year'])\n",
        "\n",
        "# JP Morgan\n",
        "grouped_jp_discussion_df = group_df(jp_discussion_df, ['quarter', 'year'])\n",
        "grouped_jp_qna_df = group_df(jp_qna_df, ['question_answer_group_id', 'quarter', 'year'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73420e11",
      "metadata": {
        "id": "73420e11"
      },
      "source": [
        "# Topic Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "23cf4579",
      "metadata": {
        "id": "23cf4579"
      },
      "outputs": [],
      "source": [
        "gs_stopwords = set(read_list_from_text_file('src/data_processing/goldman_sachs_topic_modelling_stopwords.txt'))\n",
        "abbreviations = read_yaml_file('src/abbreviations.yaml')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/pdf/2504.15683\n",
        "Use FinTextSim"
      ],
      "metadata": {
        "id": "Ctb_E-tzCBU_"
      },
      "id": "Ctb_E-tzCBU_"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b95b9b4e",
      "metadata": {
        "id": "b95b9b4e"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
        "except OSError:\n",
        "    print(\"SpaCy 'en_core_web_sm' model not found. Please run: python -m spacy download en_core_web_sm\")\n",
        "    exit()\n",
        "\n",
        "# all_stop_words = nlp.Defaults.stop_words.union(gs_stopwords)\n",
        "\n",
        "# def preprocess_text(text: str, stop_words: set, abbreviations: dict) -> str:\n",
        "#     if not isinstance(text, str):\n",
        "#         return \"\"\n",
        "\n",
        "#     processed_text = text.lower()\n",
        "#     processed_text = re.sub(r'[-_]+', ' ', processed_text).strip()\n",
        "\n",
        "#     sorted_phrases = sorted(abbreviations.items(), key=lambda item: len(item[1]), reverse=True)\n",
        "\n",
        "#     for abbrev, phrase in sorted_phrases:\n",
        "#         processed_text = re.sub(r'\\b' + re.escape(phrase.lower()) + r'\\b', abbrev.lower(), processed_text)\n",
        "\n",
        "#     processed_text = re.sub(r'\\b\\d+\\b', '', processed_text).strip()\n",
        "\n",
        "#     doc = nlp(processed_text)\n",
        "\n",
        "#     tokens = []\n",
        "#     for token in doc:\n",
        "#         if token.text not in stop_words or token.text in abbreviations.keys():\n",
        "#             tokens.append(token.lemma_) # Lemmatize the token (abbreviations won't change)\n",
        "\n",
        "#     return \" \".join(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "fb801083",
      "metadata": {
        "id": "fb801083"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.pipeline import Pipeline\n",
        "import os\n",
        "from bertopic import BERTopic\n",
        "from umap import UMAP\n",
        "import hdbscan\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "\n",
        "# --- Mock Preprocessing Function (replace with your actual preprocess_text) ---\n",
        "def preprocess_text(text, stop_words=None, abbreviations=None):\n",
        "    \"\"\"\n",
        "    A mock preprocessing function to clean and prepare text.\n",
        "    In a real application, this would include tokenization, stemming/lemmatization,\n",
        "    punctuation removal, number handling, etc.\n",
        "    \"\"\"\n",
        "    text = str(text).lower()\n",
        "    # Simple tokenization and stop word removal for demonstration\n",
        "    words = text.split()\n",
        "    if stop_words:\n",
        "        words = [word for word in words if word not in stop_words]\n",
        "    # Simple abbreviation handling (example: 'ai' -> 'artificial intelligence')\n",
        "    if abbreviations:\n",
        "        for abbr, full in abbreviations.items():\n",
        "            words = [full if word == abbr else word for word in words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "# --- Custom Transformer for Text Preprocessing ---\n",
        "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    A custom scikit-learn transformer to apply text preprocessing.\n",
        "    It wraps the 'preprocess_text' function.\n",
        "    \"\"\"\n",
        "    def __init__(self, stop_words=None, abbreviations=None):\n",
        "        self.stop_words = stop_words\n",
        "        self.abbreviations = abbreviations\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        print(\"Starting Phase 1: Preprocessing...\")\n",
        "        preprocessed_X = [preprocess_text(text, self.stop_words, self.abbreviations) for text in X]\n",
        "        print(\"Preprocessing complete.\")\n",
        "        return pd.Series(preprocessed_X)\n",
        "\n",
        "\n",
        "# --- Custom Estimator for BERTopic Modeling ---\n",
        "class BERTopicWrapper(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    A custom scikit-learn estimator that wraps BERTopic.\n",
        "    \"\"\"\n",
        "    def __init__(self, embedding_model='all-MiniLM-L6-v2', umap_args=None, hdbscan_args=None,\n",
        "                 vectorizer_args=None, nr_topics=\"auto\", calculate_probabilities=True, **bertopic_kwargs):\n",
        "\n",
        "        self.embedding_model_name = embedding_model\n",
        "        self.umap_args = umap_args if umap_args is not None else {}\n",
        "        self.hdbscan_args = hdbscan_args if hdbscan_args is not None else {}\n",
        "        self.vectorizer_args = vectorizer_args if vectorizer_args is not None else {}\n",
        "        self.nr_topics = nr_topics\n",
        "        self.calculate_probabilities = calculate_probabilities\n",
        "        self.bertopic_kwargs = bertopic_kwargs\n",
        "        self.bertopic_model = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        print(\"\\nStarting Phase 3: Topic Modeling (BERTopic)...\")\n",
        "\n",
        "        # Initialize UMAP and HDBSCAN models\n",
        "        umap_model = UMAP(**self.umap_args)\n",
        "        hdbscan_model = hdbscan.HDBSCAN(\n",
        "            min_cluster_size=10,  # Default, can be overridden by hdbscan_args\n",
        "            metric='euclidean',\n",
        "            cluster_selection_method='eom',\n",
        "            prediction_data=True, # Required for transform to assign topics to new data\n",
        "            **self.hdbscan_args\n",
        "        )\n",
        "\n",
        "        # Initialize SentenceTransformer\n",
        "        embedding_model = SentenceTransformer(self.embedding_model_name)\n",
        "\n",
        "        default_min_df_for_bertopic_vectorizer = 1 # Changed from 10 to 1 for higher permissiveness\n",
        "\n",
        "        # Combine default vectorizer args with user-provided args\n",
        "        combined_vectorizer_args = {\n",
        "            'min_df': default_min_df_for_bertopic_vectorizer,\n",
        "            'ngram_range': (1, 3), # Common default for BERTopic's internal vectorizer\n",
        "            **self.vectorizer_args # User-provided vectorizer_args will override these defaults\n",
        "        }\n",
        "\n",
        "        vectorizer_model = TfidfVectorizer(**combined_vectorizer_args)\n",
        "\n",
        "\n",
        "        self.bertopic_model = BERTopic(\n",
        "            embedding_model=embedding_model,\n",
        "            umap_model=umap_model,\n",
        "            hdbscan_model=hdbscan_model,\n",
        "            vectorizer_model=vectorizer_model,\n",
        "            nr_topics=self.nr_topics,\n",
        "            calculate_probabilities=self.calculate_probabilities,\n",
        "            **self.bertopic_kwargs\n",
        "        )\n",
        "\n",
        "        # X is expected to be a pandas Series of preprocessed text\n",
        "        self.topics, self.probs = self.bertopic_model.fit_transform(X.tolist())\n",
        "        print(\"BERTopic model fitting complete.\")\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        if self.bertopic_model is None:\n",
        "            raise RuntimeError(\"BERTopic model not fitted. Call fit() first.\")\n",
        "        print(\"Transforming data with fitted BERTopic model...\")\n",
        "        topics, probs = self.bertopic_model.transform(X.tolist())\n",
        "        print(\"Transformation complete.\")\n",
        "        return topics # Return topic assignments\n",
        "\n",
        "    def get_model(self):\n",
        "        return self.bertopic_model\n",
        "\n",
        "# --- Utility function to display topics (adapted for both LDA and BERTopic) ---\n",
        "def display_topics(model, vectorizer=None, no_top_words=10, file=None):\n",
        "    \"\"\"\n",
        "    Prints or writes the top words for each topic.\n",
        "    Args:\n",
        "        model: The fitted topic model (LDA or BERTopic).\n",
        "        vectorizer (TfidfVectorizer, optional): The fitted TF-IDF vectorizer (for LDA).\n",
        "        no_top_words (int): The number of top words to display for each topic.\n",
        "        file (file object, optional): If provided, topics will be written to this file.\n",
        "        model_type (str): 'lda' or 'bertopic' to specify model type for appropriate display.\n",
        "    \"\"\"\n",
        "    topic_info = model.get_topic_info()\n",
        "    output_str = \"\\nBERTopic - Top Words per Topic:\\n\"\n",
        "    if file:\n",
        "        file.write(output_str)\n",
        "    else:\n",
        "        print(output_str)\n",
        "\n",
        "    # Iterate through all topics, excluding the noise topic (-1)\n",
        "    for topic_id in topic_info.Topic.unique():\n",
        "        if topic_id == -1: # Skip noise topic\n",
        "            continue\n",
        "        # Get the top words for the current topic\n",
        "        words = model.get_topic(topic_id)\n",
        "        if words:\n",
        "            top_words = \", \".join([word for word, _ in words[:no_top_words]])\n",
        "            topic_name = topic_info[topic_info['Topic'] == topic_id]['Name'].iloc[0]\n",
        "            output_str = f\"Topic {topic_id} ({topic_name}): {top_words}\\n\"\n",
        "            if file:\n",
        "                file.write(output_str)\n",
        "            else:\n",
        "                print(output_str)\n",
        "        else:\n",
        "            output_str = f\"Topic {topic_id}: No words found.\\n\"\n",
        "            if file:\n",
        "                file.write(output_str)\n",
        "            else:\n",
        "                print(output_str)\n",
        "\n",
        "\n",
        "# --- Main Topic Modeling Pipeline Class ---\n",
        "class TopicModelingPipeline:\n",
        "    def __init__(self, model_type='lda', **kwargs):\n",
        "        \"\"\"\n",
        "        Initializes the topic modeling pipeline.\n",
        "\n",
        "        Args:\n",
        "            model_type (str): The type of topic model to use ('lda' or 'bertopic').\n",
        "            **kwargs: Arguments specific to the chosen model or pipeline steps.\n",
        "                      For LDA: max_df, min_df, ngram_range (for TF-IDF), n_components, max_iter, etc.\n",
        "                      For BERTopic: embedding_model, umap_args, hdbscan_args, vectorizer_args, nr_topics, etc.\n",
        "        \"\"\"\n",
        "        self.model_type = model_type\n",
        "        self.pipeline = self._build_pipeline(**kwargs)\n",
        "\n",
        "    def _build_pipeline(self, **kwargs):\n",
        "        \"\"\"Builds the scikit-learn pipeline based on the specified model_type.\"\"\"\n",
        "        preprocessor_kwargs = {\n",
        "            'stop_words': kwargs.pop('stop_words', ['a', 'the', 'is', 'and', 'of', 'to', 'in', 'for']),\n",
        "            'abbreviations': kwargs.pop('abbreviations', {'ai': 'artificial intelligence', 'ml': 'machine learning'})\n",
        "        }\n",
        "\n",
        "        pipeline_steps = [\n",
        "            ('preprocessor', TextPreprocessor(**preprocessor_kwargs))\n",
        "        ]\n",
        "\n",
        "        bertopic_kwargs = {\n",
        "            'embedding_model': kwargs.pop('embedding_model', 'all-MiniLM-L6-v2'),\n",
        "            'umap_args': kwargs.pop('umap_args', {}),\n",
        "            'hdbscan_args': kwargs.pop('hdbscan_args', {}),\n",
        "            'vectorizer_args': kwargs.pop('vectorizer_args', {}), # Pass custom vectorizer_args here\n",
        "            'nr_topics': kwargs.pop('nr_topics', \"auto\"),\n",
        "            'calculate_probabilities': kwargs.pop('calculate_probabilities', True),\n",
        "            **kwargs # Pass any remaining kwargs directly to BERTopicWrapper\n",
        "        }\n",
        "        pipeline_steps.append(('topic_modeler', BERTopicWrapper(**bertopic_kwargs)))\n",
        "\n",
        "        # Any remaining kwargs are ignored if not consumed by model-specific initializations\n",
        "        if kwargs:\n",
        "            print(f\"Warning: Unused keyword arguments passed to pipeline: {kwargs}\")\n",
        "\n",
        "        return Pipeline(pipeline_steps)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"Fits the entire pipeline to the input data.\"\"\"\n",
        "        print(f\"\\n--- Fitting {self.model_type.upper()} Topic Modeling Pipeline ---\")\n",
        "        self.pipeline.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Transforms the input data and returns topic assignments/distributions.\"\"\"\n",
        "        return self.pipeline.transform(X)\n",
        "\n",
        "    def get_topic_model(self):\n",
        "        \"\"\"Returns the underlying fitted topic model (LDA or BERTopic).\"\"\"\n",
        "        return self.pipeline.named_steps['topic_modeler'].get_model()\n",
        "\n",
        "    def get_vectorizer(self):\n",
        "        \"\"\"Returns the fitted vectorizer (TF-IDF for LDA, None for BERTopic).\"\"\"\n",
        "        if self.model_type == 'lda':\n",
        "            return self.pipeline.named_steps['tfidf_vectorizer']\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hdbscan import HDBSCAN\n",
        "\n",
        "output_dir = \"data/temp/leslie_topic_modelling_fine_tuning\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "no_top_words = 10\n",
        "bertopic_pipeline_instance = TopicModelingPipeline(\n",
        "    embedding_model='all-MiniLM-L6-v2',\n",
        "    model_type='bertopic',\n",
        "    nr_topics=\"auto\",\n",
        "    calculate_probabilities=True,\n",
        "    umap_args={'n_neighbors': 15, 'n_components': 5},\n",
        "    vectorizer_args={'min_df': 1}\n",
        ")\n",
        "bertopic_pipeline_instance.fit(grouped_gs_qna_df['content'])\n",
        "bertopic_model = bertopic_pipeline_instance.get_topic_model()\n",
        "\n",
        "output_filename_bertopic = f\"{output_dir}/bertopic_topics.txt\"\n",
        "with open(output_filename_bertopic, 'w', encoding='utf-8') as f:\n",
        "    f.write(\"--- BERTopic Model ---\\n\\n\")\n",
        "    f.write(\"Interpreting Topics:\\n\")\n",
        "    display_topics(bertopic_model, no_top_words=no_top_words, file=f, model_type='bertopic')\n",
        "print(f\"BERTopic Topics saved to {output_filename_bertopic}\")\n",
        "\n",
        "# Assign dominant topics for BERTopic\n",
        "bertopic_topic_assignments = bertopic_pipeline_instance.transform(grouped_gs_qna_df['content'])\n",
        "grouped_gs_qna_df['dominant_topic_bertopic'] = bertopic_topic_assignments\n"
      ],
      "metadata": {
        "id": "94HKBhKS-OWL",
        "outputId": "20aa5158-d91c-4516-c697-0f81feb9b788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        }
      },
      "id": "94HKBhKS-OWL",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/FinText. Creating a new one with mean pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fitting BERTOPIC Topic Modeling Pipeline ---\n",
            "Starting Phase 1: Preprocessing...\n",
            "Preprocessing complete.\n",
            "\n",
            "Starting Phase 3: Topic Modeling (BERTopic)...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "sentence-transformers/FinText is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/sentence-transformers/FinText/resolve/main/adapter_config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    471\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1007\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1009\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;31m# Unauthorized => likely a token issue => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1532\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1533\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1534\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1449\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1450\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1451\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_on_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_on_status_codes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m429\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    458\u001b[0m             )\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-68533724-366728c05648b3cc1fd44b75;93cbf3b2-240c-449b-bf7b-b38d52e61e76)\n\nRepository Not Found for url: https://huggingface.co/sentence-transformers/FinText/resolve/main/adapter_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\nInvalid username or password.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-33-435812293.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mvectorizer_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'min_df'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# Explicitly setting min_df to 1 here as a common fix for small datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mbertopic_pipeline_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouped_gs_qna_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mbertopic_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbertopic_pipeline_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_topic_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-24-1854248183.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;34m\"\"\"Fits the entire pipeline to the input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n--- Fitting {self.model_type.upper()} Topic Modeling Pipeline ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    660\u001b[0m                     \u001b[0mall_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m                 )\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlast_step_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-24-1854248183.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# Initialize SentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0membedding_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mdefault_min_df_for_bertopic_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# Changed from 10 to 1 for higher permissiveness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[1;32m    319\u001b[0m                 )\n\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                 modules = self._load_auto_model(\n\u001b[0m\u001b[1;32m    322\u001b[0m                     \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                     \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m_load_auto_model\u001b[0;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[0m\n\u001b[1;32m   1604\u001b[0m         \u001b[0mconfig_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_kwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconfig_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mshared_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1606\u001b[0;31m         transformer_model = Transformer(\n\u001b[0m\u001b[1;32m   1607\u001b[0m             \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mconfig_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_peft_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_peft_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36m_load_config\u001b[0;34m(self, model_name_or_path, cache_dir, backend, config_args)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \"\"\"\n\u001b[1;32m    120\u001b[0m         if (\n\u001b[0;32m--> 121\u001b[0;31m             find_adapter_config_file(\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/peft_utils.py\u001b[0m in \u001b[0;36mfind_adapter_config_file\u001b[0;34m(model_id, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, _commit_hash)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0madapter_cached_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mADAPTER_CONFIG_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         adapter_cached_filename = cached_file(\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mADAPTER_CONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \"\"\"\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# We cannot recover from them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGatedRepoError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             raise OSError(\n\u001b[0m\u001b[1;32m    503\u001b[0m                 \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: sentence-transformers/FinText is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9889a4cc",
      "metadata": {
        "id": "9889a4cc"
      },
      "source": [
        "Conclusion and Recommendation\n",
        "The addition of stopwords has certainly helped in some areas, making certain topics clearer. However, some conversational noise still persists, especially words related to the Q&A format or general conversational patterns. The term \"Apple\" continues to be grouped with \"deposit\" in some k values, which is still a bit puzzling without specific context.\n",
        "\n",
        "Based on this comprehensive analysis, the most sensible k value is a trade-off between granularity, coherence, and minimizing \"junk\" topics.\n",
        "\n",
        "k=8: Offers good clarity for key themes (Credit Card, Headcount/Severance, Asset/Fundraising), but is still quite broad and has some remaining conversational noise.\n",
        "k=9: Introduces very strong \"GSIB\" and \"Wealth Management\" topics.\n",
        "k=10: Shows strong \"Investment/Platform\" and \"Fundraising\" themes.\n",
        "k=11: This k value demonstrates the best balance in this new set of runs.\n",
        "It produces several very distinct and interpretable financial/business topics: \"Wealth Management/European Footprint\" , \"Severance/Headcount/Capital\" , \"Credit Card/Consumer\" , \"GSIB/Allocation\" , \"Bank/Acquisition/Advisory\" , \"FICC/Equity/Commodity\" , and \"Deposit/Capital/Market/Exposure\".\n",
        "\n",
        "Crucially, the \"Apple\" anomaly is not present in the top words of any topic for k=11, suggesting a cleaner separation of terms.\n",
        "While some conversational noise is still present (Topics 2, 4, 9 in k=11), the quality of the interpretable topics is high.\n",
        "k=12, k=13, k=14: Beyond k=11, the topics generally become more fragmented, or reintroduce the \"Apple\" anomaly, and the number of less coherent/conversational topics increases, making overall interpretation more challenging. For example, k=12 recombines \"funding/deposits\" with \"severance/headcount\", which is less ideal.\n",
        "Therefore, my strongest recommendation is k=11. It provides a good level of detail for key financial aspects of Goldman Sachs' earnings calls while offering significantly improved topic coherence and distinctiveness, and effectively mitigating some of the persistent noise terms seen in other k values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8108189b",
      "metadata": {
        "id": "8108189b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "topic_labels_map = {\n",
        "    0: \"Strategic Positioning & Platform\",\n",
        "    1: \"Wealth Management & European Markets\",\n",
        "    2: \"Alternative Investments & Fee Income\",\n",
        "    3: \"Headcount & Workforce Management\",\n",
        "    4: \"Consumer Credit & Card Performance\",\n",
        "    5: \"FICC & Equity Trading Performance\",\n",
        "    6: \"Regulatory Capital & Institutional Allocation\",\n",
        "    7: \"Client-Centric Growth & Solutions\",\n",
        "    8: \"M&A, Valuations & Advisory\",\n",
        "    9: \"FICC & Market Environment\",\n",
        "    10: \"Deposits, Capital & Funding\"\n",
        "}\n",
        "\n",
        "# Assign labels to the topics_data\n",
        "for topic_info in topics_data:\n",
        "    topic_info['label'] = topic_labels_map.get(topic_info['topic_idx'], f\"Unlabeled Topic {topic_info['topic_idx']}\")\n",
        "\n",
        "print(\"\\n--- Topics with assigned labels and top words ---\")\n",
        "for topic_info in topics_data:\n",
        "    print(f\"Topic {topic_info['topic_idx'] + 1}: {topic_info['label']}\")\n",
        "    print(f\"  Top Words: {' '.join(topic_info['top_words'])}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# --- Visual Display of Topics ---\n",
        "print(\"\\n--- Generating visual display of topics ---\")\n",
        "\n",
        "n_cols = 3\n",
        "n_rows = (num_topics + n_cols - 1) // n_cols\n",
        "plt.figure(figsize=(n_cols * 6, n_rows * 4), dpi=100)\n",
        "\n",
        "for i, topic_info in enumerate(topics_data):\n",
        "    ax = plt.subplot(n_rows, n_cols, i + 1)\n",
        "    df_plot = pd.DataFrame({\n",
        "        'word': topic_info['top_words'],\n",
        "        'weight': topic_info['word_weights']\n",
        "    })\n",
        "    df_plot = df_plot.sort_values(by='weight', ascending=True)\n",
        "    sns.barplot(x='weight', y='word', data=df_plot, palette='magma', ax=ax)\n",
        "    ax.set_title(f\"{topic_info['label']}\", fontsize=11, fontweight='bold', pad=10)\n",
        "    ax.set_xlabel(\"Word Importance (Weight)\", fontsize=9)\n",
        "    ax.set_ylabel(\"\")\n",
        "    ax.tick_params(axis='both', which='major', labelsize=8)\n",
        "    sns.despine(ax=ax, top=True, right=True, left=False, bottom=False)\n",
        "    ax.tick_params(axis='y', length=0)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
        "plt.suptitle(\n",
        "    f\"Top Words for {num_topics} Topics in Goldman Sachs Earnings Calls (Q&A Section)\",\n",
        "    y=1.00, fontsize=16, fontweight='bold'\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nVisual display generated. Please review the plots and verify the topic labels.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f760200",
      "metadata": {
        "id": "7f760200"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "959f9349",
      "metadata": {
        "id": "959f9349"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(\n",
        "    data=grouped_gs_qna_df,\n",
        "    x='year',\n",
        "    hue='quarter',\n",
        "    palette='tab10'\n",
        ")\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Documents')\n",
        "plt.title('Distribution of Documents by Year and Quarter\\nGoldman Sachs Q&A')\n",
        "plt.legend(title='Quarter')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Now, for dominant topics over both year and quarter:\n",
        "plt.figure(figsize=(16, 7))\n",
        "sns.countplot(\n",
        "    data=grouped_gs_qna_df,\n",
        "    x='dominant_topic_k11',\n",
        "    hue='year',\n",
        "    palette='tab10'\n",
        ")\n",
        "topic_labels = [topic_labels_map.get(i, f\"Topic {i}\") for i in sorted(grouped_gs_qna_df['dominant_topic_k11'].unique())]\n",
        "plt.xticks(ticks=range(len(topic_labels)), labels=topic_labels, rotation=45, ha='right')\n",
        "plt.xlabel('Dominant Topic (k=11)')\n",
        "plt.ylabel('Number of Documents')\n",
        "plt.title('Dominant Topics (k=11) by Year\\nGoldman Sachs Q&A')\n",
        "plt.legend(title='Year')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e53850b",
      "metadata": {
        "id": "6e53850b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "years = sorted(grouped_gs_qna_df['year'].unique())\n",
        "n_years = len(years)\n",
        "\n",
        "fig, axes = plt.subplots(n_years, 1, figsize=(10, 4 * n_years), sharex=True)\n",
        "\n",
        "if n_years == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for idx, year in enumerate(years):\n",
        "    ax = axes[idx]\n",
        "    data = grouped_gs_qna_df[grouped_gs_qna_df['year'] == year]\n",
        "    sns.countplot(\n",
        "        data=data,\n",
        "        x='quarter',\n",
        "        hue='dominant_topic_k11',\n",
        "        palette='tab10',\n",
        "        ax=ax\n",
        "    )\n",
        "    ax.set_title(f'Distribution of Dominant Topics (k=11) by Quarter - {year}')\n",
        "    ax.set_xlabel('Quarter')\n",
        "    ax.set_ylabel('Number of Documents')\n",
        "    ax.legend(\n",
        "        title='Dominant Topic',\n",
        "        loc='upper right',\n",
        "        labels=[topic_labels_map.get(i, f\"Topic {i}\") for i in sorted(data['dominant_topic_k11'].unique())]\n",
        "    )\n",
        "\n",
        "# Fix color mapping so each topic always has the same color across years\n",
        "unique_topics = sorted(grouped_gs_qna_df['dominant_topic_k11'].unique())\n",
        "topic_palette = sns.color_palette('tab10', n_colors=len(unique_topics))\n",
        "topic_color_dict = {topic: topic_palette[i % len(topic_palette)] for i, topic in enumerate(unique_topics)}\n",
        "\n",
        "for idx, year in enumerate(years):\n",
        "    ax = axes[idx]\n",
        "    data = grouped_gs_qna_df[grouped_gs_qna_df['year'] == year]\n",
        "    # Use the same color mapping for all years\n",
        "    sns.countplot(\n",
        "        data=data,\n",
        "        x='quarter',\n",
        "        hue='dominant_topic_k11',\n",
        "        palette=topic_color_dict,\n",
        "        ax=ax\n",
        "    )\n",
        "    ax.set_title(f'Distribution of Dominant Topics (k=11) by Quarter - {year}')\n",
        "    ax.set_xlabel('Quarter')\n",
        "    ax.set_ylabel('Number of Documents')\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    # Always use the same order and labels for legend\n",
        "    ordered_labels = [topic_labels_map.get(t, f\"Topic {t}\") for t in unique_topics]\n",
        "    ax.legend(handles, ordered_labels, title='Dominant Topic', loc='upper right')\n",
        "\n",
        "plt.suptitle(\n",
        "    \"Quarterly Distribution of Dominant Topics (k=11) by Year\\nGoldman Sachs Earnings Call Transcript (Q&A Section)\",\n",
        "    fontsize=16, fontweight='bold', y=1.02\n",
        ")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7817bea",
      "metadata": {
        "id": "f7817bea"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8f10d7a1",
      "metadata": {
        "id": "8f10d7a1"
      },
      "source": [
        "# Save Data Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb15dc4f",
      "metadata": {
        "id": "bb15dc4f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "target_dir = 'data/temp/'\n",
        "file_name = 'dummy_test_output_new.csv'\n",
        "dummy_pf = pd.DataFrame({'from_colab': [IS_COLAB, True, 'hello']})\n",
        "\n",
        "\n",
        "if OUTPUT_PROCESSED_FILES:\n",
        "    if IS_COLAB:\n",
        "        AUTHENTICATED_REPO_URL = REPO_URL.replace(\"https://\", f\"https://{GITHUB_USERNAME}:{GITHUB_TOKEN}@\")\n",
        "        dummy_pf.to_csv(f\"{target_dir}{file_name}\", index=False)\n",
        "\n",
        "        # Configure Git user (important for committing)\n",
        "        !git config user.email \"{GITHUB_EMAIL}\"\n",
        "        !git config user.name \"{GITHUB_USERNAME}\"\n",
        "        !git remote set-url origin {AUTHENTICATED_REPO_URL}\n",
        "\n",
        "        # Add the file to staging\n",
        "        !git add {target_dir}{file_name}\n",
        "        print(f\"Added '{target_dir}{file_name}' to staging.\")\n",
        "\n",
        "        # Commit the changes\n",
        "        commit_message = f\"Add new data file: {target_dir}{file_name}\"\n",
        "        !git commit -m \"{commit_message}\"\n",
        "        print(f\"Committed changes with message: '{commit_message}'\")\n",
        "        print(f\"Attempted commit with message: '{commit_message}'\")\n",
        "\n",
        "        # Add this line to debug:\n",
        "        print(f\"Value of REPO_BRANCH before push: {REPO_BRANCH}\")\n",
        "\n",
        "        print(\"Pushing changes to GitHub. Please enter your GitHub username and Personal Access Token when prompted.\")\n",
        "        !git push --set-upstream origin {REPO_BRANCH} --force\n",
        "        print(\"Push command executed. Check output for success or prompt.\")\n",
        "    else:\n",
        "        dummy_pf.to_csv(f\"{target_dir}{file_name}\", index=False)\n",
        "        print(\"Processed files saved successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QAa-7pTX73f4",
      "metadata": {
        "id": "QAa-7pTX73f4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0rc2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}